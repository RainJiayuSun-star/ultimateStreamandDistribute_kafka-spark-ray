services:
  # Kafka Broker + Producer (Combined)
  kafka:
    build:
      context: .
      dockerfile: Dockerfile.kafka
    container_name: kafka
    hostname: kafka
    mem_limit: 2g
    cpus: 1
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CLUSTER_ID=dCHffFWYTCKWXiesmJMN9w
    volumes:
      - ./src:/app/src:ro
      - kafka-data:/kafka_2.12-3.6.2/data
    networks:
      - weather-network
    healthcheck:
      test: ["CMD", "netstat", "-tuln", "|", "grep", "9092"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Spark Master
  spark-master:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-master
    hostname: spark-master
    mem_limit: 2g
    cpus: 1
    ports:
      - "8080:8080"  # Spark Master UI
      - "7077:7077"  # Spark Master port
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
      - spark-checkpoints:/app/checkpoints
    networks:
      - weather-network
    command: >
      sh -c "spark-class org.apache.spark.deploy.master.Master
      --host spark-master
      --port 7077
      --webui-port 8080"
    depends_on:
      kafka:
        condition: service_healthy

  # Spark Workers (4 workers)
  spark-worker:
    build:
      context: .
      dockerfile: Dockerfile.spark
    mem_limit: 3g
    cpus: 1
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=3g
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
      - spark-checkpoints:/app/checkpoints
    networks:
      - weather-network
    command: >
      sh -c "spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
      --cores 1
      --memory 3g"
    depends_on:
      - spark-master
    deploy:
      replicas: 4

  # Ray Head
  ray-head:
    build:
      context: .
      dockerfile: Dockerfile.ray
    container_name: ray-head
    hostname: ray-head
    mem_limit: 2g
    cpus: 1
    ports:
      - "8265:8265"  # Ray Dashboard
      - "6379:6379"  # Ray GCS port
    environment:
      - RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE=1
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
    networks:
      - weather-network
    command: >
      sh -c "ray start --head
      --port=6379
      --dashboard-host=0.0.0.0
      --dashboard-port=8265
      --num-cpus=1
      --object-store-memory=1000000000"
    depends_on:
      - kafka

  # Ray Workers (4 workers)
  ray-worker:
    build:
      context: .
      dockerfile: Dockerfile.ray
    mem_limit: 3g
    cpus: 1
    environment:
      - RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE=1
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
    networks:
      - weather-network
    command: >
      sh -c "ray start
      --address=ray-head:6379
      --num-cpus=1
      --num-gpus=0
      --object-store-memory=2000000000"
    depends_on:
      - ray-head
    deploy:
      replicas: 4

  # API and Dashboard
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: api
    hostname: api
    mem_limit: 2g
    cpus: 1
    ports:
      - "5000:5000"  # API port
    environment:
      - FLASK_ENV=production
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    volumes:
      - ./src:/app/src:ro
    networks:
      - weather-network
    depends_on:
      - kafka
      - ray-head
    command: ["python3", "/app/api/app.py"]

# Networks
networks:
  weather-network:
    driver: bridge
    name: weather-network

# Volumes
volumes:
  kafka-data:
    name: kafka-data
  spark-checkpoints:
    name: spark-checkpoints

