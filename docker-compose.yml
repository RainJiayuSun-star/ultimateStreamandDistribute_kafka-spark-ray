services:
  # Kafka Broker + Producer (Combined)
  kafka:
    build:
      context: .
      dockerfile: Dockerfile.kafka
    image: kafka
    container_name: kafka
    hostname: kafka
    mem_limit: 2g
    cpus: 1
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CLUSTER_ID=dCHffFWYTCKWXiesmJMN9w
    volumes:
      - ./src:/app/src:ro
      - kafka-data:/kafka_2.12-3.6.2/data
    networks:
      - weather-network
    healthcheck:
      test: ["CMD", "netstat", "-tuln", "|", "grep", "9092"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka Data Collector (saves raw data to files)
  kafka-data-collector:
    image: kafka
    container_name: kafka-data-collector
    hostname: kafka-data-collector
    mem_limit: 1g
    cpus: 0.5
    volumes:
      - ./src:/app/src:ro
      - ./src/data/kafka_streaming:/app/data/kafka_streaming
    networks:
      - weather-network
    command: >
      sh -c "sleep 10 && python3 /app/src/kafka_weather/data_collector.py"
    depends_on:
      kafka:
        condition: service_healthy
    restart: unless-stopped

  # Spark Master
  spark-master:
    build:
      context: .
      dockerfile: Dockerfile.spark
    image: spark-master
    container_name: spark-master
    hostname: spark-master
    mem_limit: 2g
    cpus: 1
    ports:
      - "8080:8080"  # Spark Master UI
      - "7077:7077"  # Spark Master port
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
      - spark-checkpoints:/app/checkpoints
    networks:
      - weather-network
    command: >
      sh -c "spark-class org.apache.spark.deploy.master.Master
      --host spark-master
      --port 7077
      --webui-port 8080"
    depends_on:
      kafka:
        condition: service_healthy

  # Spark Workers (4 workers)
  spark-worker1:
    build:
      context: .
      dockerfile: Dockerfile.spark
    image: spark-worker
    container_name: spark-worker1
    hostname: spark-worker1
    mem_limit: 3g
    cpus: 1
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=3g
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
      - spark-checkpoints:/app/checkpoints
    networks:
      - weather-network
    command: >
      sh -c "spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
      --cores 1
      --memory 3g"
    depends_on:
      - spark-master

  spark-worker2:
    image: spark-worker
    container_name: spark-worker2
    hostname: spark-worker2
    mem_limit: 3g
    cpus: 1
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=3g
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
      - spark-checkpoints:/app/checkpoints
    networks:
      - weather-network
    command: >
      sh -c "spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
      --cores 1
      --memory 3g"
    depends_on:
      - spark-master

  spark-worker3:
    image: spark-worker
    container_name: spark-worker3
    hostname: spark-worker3
    mem_limit: 3g
    cpus: 1
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=3g
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
      - spark-checkpoints:/app/checkpoints
    networks:
      - weather-network
    command: >
      sh -c "spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
      --cores 1
      --memory 3g"
    depends_on:
      - spark-master

  spark-worker4:
    image: spark-worker
    container_name: spark-worker4
    hostname: spark-worker4
    mem_limit: 3g
    cpus: 1
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=3g
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
      - spark-checkpoints:/app/checkpoints
    networks:
      - weather-network
    command: >
      sh -c "spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
      --cores 1
      --memory 3g"
    depends_on:
      - spark-master

  # Spark Streaming Application
  spark-streaming:
    image: spark-worker
    container_name: spark-streaming
    hostname: spark-streaming
    mem_limit: 2g
    cpus: 1
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./src:/app/src:ro
      - spark-checkpoints:/app/checkpoints
    networks:
      - weather-network
    command: >
      sh -c "sleep 30 && /app/start_spark_streaming.sh"
    depends_on:
      - spark-master
      - kafka
    restart: unless-stopped

  # Ray Head
  ray-head:
    build:
      context: .
      dockerfile: Dockerfile.ray
    image: ray-head
    container_name: ray-head
    hostname: ray-head
    mem_limit: 2g
    cpus: 1
    ports:
      - "8265:8265"  # Ray Dashboard
      - "6379:6379"  # Ray GCS port
    environment:
      - RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE=1
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
    networks:
      - weather-network
    command: >
      sh -c "ray start --head
      --port=6379
      --dashboard-host=0.0.0.0
      --dashboard-port=8265
      --num-cpus=1
      --object-store-memory=1000000000"
    depends_on:
      - kafka

  # Ray Workers (4 workers)
  ray-worker1:
    build:
      context: .
      dockerfile: Dockerfile.ray
    image: ray-worker
    container_name: ray-worker1
    hostname: ray-worker1
    mem_limit: 3g
    cpus: 1
    environment:
      - RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE=1
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
    networks:
      - weather-network
    command: >
      sh -c "ray start
      --address=ray-head:6379
      --num-cpus=1
      --num-gpus=0
      --object-store-memory=2000000000"
    depends_on:
      - ray-head

  ray-worker2:
    image: ray-worker
    container_name: ray-worker2
    hostname: ray-worker2
    mem_limit: 3g
    cpus: 1
    environment:
      - RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE=1
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
    networks:
      - weather-network
    command: >
      sh -c "ray start
      --address=ray-head:6379
      --num-cpus=1
      --num-gpus=0
      --object-store-memory=2000000000"
    depends_on:
      - ray-head

  ray-worker3:
    image: ray-worker
    container_name: ray-worker3
    hostname: ray-worker3
    mem_limit: 3g
    cpus: 1
    environment:
      - RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE=1
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
    networks:
      - weather-network
    command: >
      sh -c "ray start
      --address=ray-head:6379
      --num-cpus=1
      --num-gpus=0
      --object-store-memory=2000000000"
    depends_on:
      - ray-head

  ray-worker4:
    image: ray-worker
    container_name: ray-worker4
    hostname: ray-worker4
    mem_limit: 3g
    cpus: 1
    environment:
      - RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE=1
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
    networks:
      - weather-network
    command: >
      sh -c "ray start
      --address=ray-head:6379
      --num-cpus=1
      --num-gpus=0
      --object-store-memory=2000000000"
    depends_on:
      - ray-head

  # API and Dashboard
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    image: api
    container_name: api
    hostname: api
    mem_limit: 2g
    cpus: 1
    ports:
      - "5000:5000"  # API port
    environment:
      - FLASK_ENV=production
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    volumes:
      - ./src:/app/src:ro
    networks:
      - weather-network
    depends_on:
      - kafka
      - ray-head
    command: ["python3", "/app/api/app.py"]

# Networks
networks:
  weather-network:
    driver: bridge
    name: weather-network

# Volumes
volumes:
  kafka-data:
    name: kafka-data
  spark-checkpoints:
    name: spark-checkpoints

